{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn-crfsuite in c:\\users\\martin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (0.3.6)\n",
      "Requirement already satisfied: six in c:\\users\\martin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from sklearn-crfsuite) (1.16.0)\n",
      "Requirement already satisfied: tqdm>=2.0 in c:\\users\\martin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from sklearn-crfsuite) (4.62.3)\n",
      "Requirement already satisfied: tabulate in c:\\users\\martin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from sklearn-crfsuite) (0.8.9)\n",
      "Requirement already satisfied: python-crfsuite>=0.8.3 in c:\\users\\martin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from sklearn-crfsuite) (0.9.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\martin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tqdm>=2.0->sklearn-crfsuite) (0.4.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.1.1; however, version 23.0.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\martin\\appdata\\local\\programs\\python\\python38\\python.exe -m pip install --upgrade pip' command.\n",
      "ERROR: Could not find a version that satisfies the requirement sklearn-grid_search (from versions: none)\n",
      "ERROR: No matching distribution found for sklearn-grid_search\n",
      "WARNING: You are using pip version 21.1.1; however, version 23.0.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\martin\\appdata\\local\\programs\\python\\python38\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn-crfsuite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn==0.23.2\n",
      "  Downloading scikit_learn-0.23.2-cp38-cp38-win_amd64.whl (6.8 MB)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\martin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-learn==0.23.2) (1.21.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\martin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-learn==0.23.2) (3.0.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\martin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-learn==0.23.2) (1.7.3)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\martin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-learn==0.23.2) (1.1.0)\n",
      "Installing collected packages: scikit-learn\n",
      "Successfully installed scikit-learn-0.23.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.1.1; however, version 23.0.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\Martin\\AppData\\Local\\Programs\\Python\\Python38\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install --user -U scikit-learn==0.23.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import sklearn_crfsuite\n",
    "# import math\n",
    "\n",
    "from sklearn_crfsuite import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "# from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "import scipy.stats\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "# from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "WINDOW = 7\n",
    "\n",
    "def build_dataframe(file_path):\n",
    "    data = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            data.append(line.strip().split('\\t'))\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    df = df.rename(columns={0: 'file', 1: 'sentence', 2: 'position', 3: 'token', 4: 'negCue'})\n",
    "\n",
    "    #drop empty rows\n",
    "    df = df.drop(df[(df.file == '')].index)\n",
    "\n",
    "    df.insert(len(df.columns)-1, 'lemma', None)\n",
    "    df.insert(len(df.columns)-1, 'postag', None)\n",
    "\n",
    "    for i in range(1,(WINDOW+1)):\n",
    "        df.insert(len(df.columns)-1, f'lemma_a{i}', None)  #lemma of token 1-position AFTER  token\n",
    "        df.insert(len(df.columns)-1, f'lemma_b{i}', None)  #lemma of token 1-position BEFORE  token\n",
    "\n",
    "        df.insert(len(df.columns)-1, f'pos_a{i}', None)    #postag of token 1-position AFTER  token\n",
    "        df.insert(len(df.columns)-1, f'pos_b{i}', None)    #postag of token 1-position BEFORE  token\n",
    "\n",
    "    df.insert(len(df.columns)-1, 'known_cue', None)        #if token was seen as a cue during training\n",
    "\n",
    "    df = df.astype({'sentence': 'int32'})\n",
    "    df = df.astype({'position': 'int32'})\n",
    "\n",
    "    #Encode golden label\n",
    "    negCue_dict = {\"negCue\":     {\"O\": '0', \"B-NEG\": '1', \"I-NEG\": '2'}}\n",
    "    df = df.replace(negCue_dict)    \n",
    "\n",
    "    return df\n",
    "\n",
    "def feature_extraction(dataframe,known_cues=[]):\n",
    "\n",
    "    column_names = dataframe.columns\n",
    "    new_df = pd.DataFrame(columns=column_names)\n",
    "\n",
    "    for _file in dataframe.file.unique():\n",
    "        file_df = dataframe[dataframe['file']==_file]\n",
    "\n",
    "        file_df = file_df.groupby(['sentence']).apply(applySentenceGroupBy)\n",
    "\n",
    "        new_df = new_df.append(file_df)\n",
    "\n",
    "    dataframe = new_df\n",
    "\n",
    "    dataframe = set_known_cue_feature(dataframe,known_cues)\n",
    "\n",
    "    return dataframe\n",
    "\n",
    "def set_known_cue_feature(df,cues):\n",
    "    new_df = pd.DataFrame(columns=df.columns)\n",
    "    \n",
    "    for i,row in df.iterrows():\n",
    "        row['known_cue'] = True if row['token'] in cues else False\n",
    "        new_df = new_df.append(row,ignore_index=True)\n",
    "\n",
    "    return new_df\n",
    "            \n",
    "def applySentenceGroupBy(sentence_df):\n",
    "    \n",
    "    tokens = []\n",
    "    for i,row in sentence_df.iterrows():\n",
    "        tokens.append(row['token'])\n",
    "    \n",
    "    #reconstruct sentence from original df\n",
    "    string = ' '.join([token for token in tokens])\n",
    "    \n",
    "    #use spacy to tokenize and extract info from sentence\n",
    "    spacy_tokenized = nlp(string)\n",
    "    \n",
    "    sentence_df = add_token_features(sentence_df,spacy_tokenized,offset=1)    \n",
    "    \n",
    "    return sentence_df    \n",
    "\n",
    "def add_token_features(sentence_df,spacy_tokenized,offset=1):\n",
    "    i=0\n",
    "    # tokens = [token for token in spacy_tokenized]\n",
    "    \n",
    "    sentence_ = pd.DataFrame(columns=sentence_df.columns)\n",
    "    for idx,row in sentence_df.iterrows():\n",
    "        \n",
    "        # Both tokenizarions match:\n",
    "        if row['token'] == spacy_tokenized[i].text:\n",
    "\n",
    "            row = set_lemma_and_pos(row,spacy_tokenized,i)\n",
    "        else:\n",
    "            \n",
    "            if row['token'] == spacy_tokenized[i-offset].text:\n",
    "                row = set_lemma_and_pos(row,spacy_tokenized,i-offset)\n",
    "            elif row['token'] == spacy_tokenized[i+offset].text:\n",
    "                row = set_lemma_and_pos(row,spacy_tokenized,i+offset)\n",
    "            else:\n",
    "                #try one position more\n",
    "                \n",
    "                if row['token'] == spacy_tokenized[i-offset+1].text:\n",
    "                    row = set_lemma_and_pos(row,spacy_tokenized,i-offset+1)\n",
    "                elif row['token'] == spacy_tokenized[i+offset+1].text:\n",
    "                    row = set_lemma_and_pos(row,spacy_tokenized,i+offset+1)                \n",
    "\n",
    "        sentence_ = sentence_.append(row,ignore_index=True)\n",
    "        i += 1\n",
    "    \n",
    "    return sentence_\n",
    "\n",
    "def set_lemma_and_pos(row,spacy_tokenized,idx):\n",
    "    #Lemma\n",
    "    row['lemma']          = spacy_tokenized[idx].lemma_\n",
    "    row['postag']         = spacy_tokenized[idx].tag_\n",
    "\n",
    "    for i in range (1,(WINDOW+1)):\n",
    "        row[f'lemma_b{i}']       = spacy_tokenized[idx-i].lemma_ if (idx + (1-i)) > 0 else None \n",
    "        row[f'lemma_a{i}']       = spacy_tokenized[idx+i].lemma_ if (idx+i) < len(spacy_tokenized) else None\n",
    "\n",
    "        row[f'pos_b{i}']       = spacy_tokenized[idx-i].tag_ if (idx + (1-i)) > 0 else None \n",
    "        row[f'pos_a{i}']       = spacy_tokenized[idx+i].tag_ if (idx+i) < len(spacy_tokenized) else None\n",
    "\n",
    "    return row\n",
    "\n",
    "def get_training_cues(train_df):\n",
    "    # print(train_df.head())\n",
    "    cues= train_df.loc[(train_df['negCue']=='1')| (train_df['negCue']==1)]['token'].tolist()\n",
    "\n",
    "    cues = list(set(cues)) #remove duplicates\n",
    "\n",
    "    return cues\n",
    "\n",
    "def dataframe2features(dataframe,known_cues=True,window=7):\n",
    "    tokens = []\n",
    "    labels = []\n",
    "    for sentence_id, group in dataframe.groupby(['file','sentence']): #TODO arreglar esto para cuando saque el BREAK de files\n",
    "        token = []\n",
    "        label = []\n",
    "        for _, row in group.iterrows():\n",
    "            token_dict = {'token': row['token'],\n",
    "                            'file': row['file'],\n",
    "                            'sentence': row['sentence'],\n",
    "                            'position': row['position']\n",
    "                        }\n",
    "            if known_cues:\n",
    "                token_dict['known_cue'] = row['known_cue']\n",
    "            \n",
    "            if row['lemma'] != None:\n",
    "                token_dict['lemma'] = row['lemma']\n",
    "            if row['postag'] != None:\n",
    "                token_dict['postag'] = row['postag']\n",
    "            \n",
    "            for i in range(1,window+1):\n",
    "                if str(row[f'lemma_a{i}']) != 'nan':\n",
    "                    token_dict[f'lemma_a{i}'] = row[f'lemma_a{i}']\n",
    "                if str(row[f'lemma_b{i}']) != 'nan':\n",
    "                    token_dict[f'lemma_b{i}'] = row[f'lemma_b{i}']                    \n",
    "                if str(row[f'pos_b{i}']) != 'nan':\n",
    "                    token_dict[f'pos_b{i}'] = row[f'pos_b{i}']                                        \n",
    "                if str(row[f'pos_a{i}']) != 'nan':\n",
    "                    token_dict[f'pos_a{i}'] = row[f'pos_a{i}']                                                            \n",
    "\n",
    "            # if row['negCue'] != None:\n",
    "            #     token_dict['negCue'] = row['negCue']\n",
    "\n",
    "\n",
    "            token.append(token_dict)\n",
    "            label.append(str(row['negCue']))\n",
    "        tokens.append(token)\n",
    "        labels.append(label)\n",
    "\n",
    "    return tokens,labels\n",
    "\n",
    "def train_crf_and_predict(X_train,y_train,X_test,y_test):\n",
    "    crf = sklearn_crfsuite.CRF(\n",
    "        algorithm='lbfgs',\n",
    "        c1=0.1,\n",
    "        c2=0.1,\n",
    "        max_iterations=100,\n",
    "        all_possible_transitions=True\n",
    "    )\n",
    "\n",
    "    crf.fit(X_train, y_train)\n",
    "\n",
    "    labels = list(crf.classes_)\n",
    "    sorted_labels = sorted(labels, key=lambda name: (name[1:], name[0]))\n",
    "\n",
    "    y_pred = crf.predict(X_test)\n",
    "    y_pred_ = []\n",
    "\n",
    "    for sentence_preds in y_pred:\n",
    "        y_pred_.extend(sentence_preds)\n",
    "\n",
    "    y_test = y_test.astype({'negCue': str})\n",
    "\n",
    "    report = classification_report(y_test, y_pred_, target_names=sorted_labels)\n",
    "    print(report)\n",
    "\n",
    "\n",
    "    return crf,report\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing and Feature Engineering (TRAIN AND TEST DFs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess & save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>sentence</th>\n",
       "      <th>position</th>\n",
       "      <th>token</th>\n",
       "      <th>lemma</th>\n",
       "      <th>postag</th>\n",
       "      <th>lemma_a1</th>\n",
       "      <th>lemma_b1</th>\n",
       "      <th>pos_a1</th>\n",
       "      <th>pos_b1</th>\n",
       "      <th>...</th>\n",
       "      <th>lemma_a6</th>\n",
       "      <th>lemma_b6</th>\n",
       "      <th>pos_a6</th>\n",
       "      <th>pos_b6</th>\n",
       "      <th>lemma_a7</th>\n",
       "      <th>lemma_b7</th>\n",
       "      <th>pos_a7</th>\n",
       "      <th>pos_b7</th>\n",
       "      <th>known_cue</th>\n",
       "      <th>negCue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baskervilles01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Chapter</td>\n",
       "      <td>chapter</td>\n",
       "      <td>NN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>baskervilles01</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>baskervilles01</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>NNP</td>\n",
       "      <td>Sherlock</td>\n",
       "      <td>.</td>\n",
       "      <td>NNP</td>\n",
       "      <td>.</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>baskervilles01</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Sherlock</td>\n",
       "      <td>Sherlock</td>\n",
       "      <td>NNP</td>\n",
       "      <td>Holmes</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NNP</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>baskervilles01</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Holmes</td>\n",
       "      <td>Holmes</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sherlock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65446</th>\n",
       "      <td>baskervilles14</td>\n",
       "      <td>270</td>\n",
       "      <td>58</td>\n",
       "      <td>slopes</td>\n",
       "      <td>slope</td>\n",
       "      <td>NNS</td>\n",
       "      <td>of</td>\n",
       "      <td>russet</td>\n",
       "      <td>IN</td>\n",
       "      <td>NN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>until</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>away</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RB</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65447</th>\n",
       "      <td>baskervilles14</td>\n",
       "      <td>270</td>\n",
       "      <td>59</td>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>the</td>\n",
       "      <td>slope</td>\n",
       "      <td>DT</td>\n",
       "      <td>NNS</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>it</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PRP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>until</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IN</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65448</th>\n",
       "      <td>baskervilles14</td>\n",
       "      <td>270</td>\n",
       "      <td>60</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>moor</td>\n",
       "      <td>of</td>\n",
       "      <td>NN</td>\n",
       "      <td>IN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>merge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VBD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>it</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PRP</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65449</th>\n",
       "      <td>baskervilles14</td>\n",
       "      <td>270</td>\n",
       "      <td>61</td>\n",
       "      <td>moor</td>\n",
       "      <td>moor</td>\n",
       "      <td>NN</td>\n",
       "      <td>.</td>\n",
       "      <td>the</td>\n",
       "      <td>.</td>\n",
       "      <td>DT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>into</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>merge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VBD</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65450</th>\n",
       "      <td>baskervilles14</td>\n",
       "      <td>270</td>\n",
       "      <td>62</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>moor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>into</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IN</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65451 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 file  sentence  position     token     lemma postag  \\\n",
       "0      baskervilles01         0         0   Chapter   chapter     NN   \n",
       "1      baskervilles01         0         1        1.       NaN    NaN   \n",
       "2      baskervilles01         0         2       Mr.       Mr.    NNP   \n",
       "3      baskervilles01         0         3  Sherlock  Sherlock    NNP   \n",
       "4      baskervilles01         0         4    Holmes    Holmes    NNP   \n",
       "...               ...       ...       ...       ...       ...    ...   \n",
       "65446  baskervilles14       270        58    slopes     slope    NNS   \n",
       "65447  baskervilles14       270        59        of        of     IN   \n",
       "65448  baskervilles14       270        60       the       the     DT   \n",
       "65449  baskervilles14       270        61      moor      moor     NN   \n",
       "65450  baskervilles14       270        62         .         .      .   \n",
       "\n",
       "       lemma_a1  lemma_b1 pos_a1 pos_b1  ... lemma_a6 lemma_b6 pos_a6 pos_b6  \\\n",
       "0             1       NaN     CD    NaN  ...      NaN      NaN    NaN    NaN   \n",
       "1           NaN       NaN    NaN    NaN  ...      NaN      NaN    NaN    NaN   \n",
       "2      Sherlock         .    NNP      .  ...      NaN      NaN    NaN    NaN   \n",
       "3        Holmes       Mr.    NNP    NNP  ...      NaN      NaN    NaN    NaN   \n",
       "4           NaN  Sherlock    NaN    NNP  ...      NaN      NaN    NaN    NaN   \n",
       "...         ...       ...    ...    ...  ...      ...      ...    ...    ...   \n",
       "65446        of    russet     IN     NN  ...      NaN    until    NaN     IN   \n",
       "65447       the     slope     DT    NNS  ...      NaN       it    NaN    PRP   \n",
       "65448      moor        of     NN     IN  ...      NaN    merge    NaN    VBD   \n",
       "65449         .       the      .     DT  ...      NaN     into    NaN     IN   \n",
       "65450       NaN      moor    NaN     NN  ...      NaN      the    NaN     DT   \n",
       "\n",
       "      lemma_a7 lemma_b7 pos_a7 pos_b7 known_cue negCue  \n",
       "0          NaN      NaN    NaN    NaN     False      0  \n",
       "1          NaN      NaN    NaN    NaN     False      0  \n",
       "2          NaN      NaN    NaN    NaN     False      0  \n",
       "3          NaN      NaN    NaN    NaN     False      0  \n",
       "4          NaN      NaN    NaN    NaN     False      0  \n",
       "...        ...      ...    ...    ...       ...    ...  \n",
       "65446      NaN     away    NaN     RB     False      0  \n",
       "65447      NaN    until    NaN     IN     False      0  \n",
       "65448      NaN       it    NaN    PRP     False      0  \n",
       "65449      NaN    merge    NaN    VBD     False      0  \n",
       "65450      NaN     into    NaN     IN     False      0  \n",
       "\n",
       "[65451 rows x 36 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = build_dataframe(\"corpus/SEM-2012-SharedTask-CD-SCO-training-simple.v2.txt\")\n",
    "test_df = build_dataframe(\"corpus/SEM-2012-SharedTask-CD-SCO-dev-simple.v2.txt\")\n",
    "\n",
    "known_cues = get_training_cues(train_df)\n",
    "\n",
    "train_df = feature_extraction(train_df,known_cues)\n",
    "test_df = feature_extraction(test_df,known_cues)\n",
    "\n",
    "train_df.to_csv('corpus/train_df_preproc.csv', sep='\\t',index=False)\n",
    "test_df.to_csv('corpus/test_df_preproc.csv', sep='\\t',index=False)\n",
    "\n",
    "train_df = pd.read_csv('corpus/train_df_preproc.csv', sep='\\t')\n",
    "test_df = pd.read_csv('corpus/test_df_preproc.csv', sep='\\t')\n",
    "\n",
    "train_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read preprocessed DFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>sentence</th>\n",
       "      <th>position</th>\n",
       "      <th>token</th>\n",
       "      <th>lemma</th>\n",
       "      <th>postag</th>\n",
       "      <th>lemma_a1</th>\n",
       "      <th>lemma_b1</th>\n",
       "      <th>pos_a1</th>\n",
       "      <th>pos_b1</th>\n",
       "      <th>...</th>\n",
       "      <th>lemma_a6</th>\n",
       "      <th>lemma_b6</th>\n",
       "      <th>pos_a6</th>\n",
       "      <th>pos_b6</th>\n",
       "      <th>lemma_a7</th>\n",
       "      <th>lemma_b7</th>\n",
       "      <th>pos_a7</th>\n",
       "      <th>pos_b7</th>\n",
       "      <th>known_cue</th>\n",
       "      <th>negCue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baskervilles01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Chapter</td>\n",
       "      <td>chapter</td>\n",
       "      <td>NN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>baskervilles01</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>baskervilles01</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>NNP</td>\n",
       "      <td>Sherlock</td>\n",
       "      <td>.</td>\n",
       "      <td>NNP</td>\n",
       "      <td>.</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>baskervilles01</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Sherlock</td>\n",
       "      <td>Sherlock</td>\n",
       "      <td>NNP</td>\n",
       "      <td>Holmes</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NNP</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>baskervilles01</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Holmes</td>\n",
       "      <td>Holmes</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sherlock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65446</th>\n",
       "      <td>baskervilles14</td>\n",
       "      <td>270</td>\n",
       "      <td>58</td>\n",
       "      <td>slopes</td>\n",
       "      <td>slope</td>\n",
       "      <td>NNS</td>\n",
       "      <td>of</td>\n",
       "      <td>russet</td>\n",
       "      <td>IN</td>\n",
       "      <td>NN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>until</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>away</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RB</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65447</th>\n",
       "      <td>baskervilles14</td>\n",
       "      <td>270</td>\n",
       "      <td>59</td>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>the</td>\n",
       "      <td>slope</td>\n",
       "      <td>DT</td>\n",
       "      <td>NNS</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>it</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PRP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>until</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IN</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65448</th>\n",
       "      <td>baskervilles14</td>\n",
       "      <td>270</td>\n",
       "      <td>60</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>moor</td>\n",
       "      <td>of</td>\n",
       "      <td>NN</td>\n",
       "      <td>IN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>merge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VBD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>it</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PRP</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65449</th>\n",
       "      <td>baskervilles14</td>\n",
       "      <td>270</td>\n",
       "      <td>61</td>\n",
       "      <td>moor</td>\n",
       "      <td>moor</td>\n",
       "      <td>NN</td>\n",
       "      <td>.</td>\n",
       "      <td>the</td>\n",
       "      <td>.</td>\n",
       "      <td>DT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>into</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>merge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VBD</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65450</th>\n",
       "      <td>baskervilles14</td>\n",
       "      <td>270</td>\n",
       "      <td>62</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>moor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>into</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IN</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65451 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 file  sentence  position     token     lemma postag  \\\n",
       "0      baskervilles01         0         0   Chapter   chapter     NN   \n",
       "1      baskervilles01         0         1        1.       NaN    NaN   \n",
       "2      baskervilles01         0         2       Mr.       Mr.    NNP   \n",
       "3      baskervilles01         0         3  Sherlock  Sherlock    NNP   \n",
       "4      baskervilles01         0         4    Holmes    Holmes    NNP   \n",
       "...               ...       ...       ...       ...       ...    ...   \n",
       "65446  baskervilles14       270        58    slopes     slope    NNS   \n",
       "65447  baskervilles14       270        59        of        of     IN   \n",
       "65448  baskervilles14       270        60       the       the     DT   \n",
       "65449  baskervilles14       270        61      moor      moor     NN   \n",
       "65450  baskervilles14       270        62         .         .      .   \n",
       "\n",
       "       lemma_a1  lemma_b1 pos_a1 pos_b1  ... lemma_a6 lemma_b6 pos_a6 pos_b6  \\\n",
       "0             1       NaN     CD    NaN  ...      NaN      NaN    NaN    NaN   \n",
       "1           NaN       NaN    NaN    NaN  ...      NaN      NaN    NaN    NaN   \n",
       "2      Sherlock         .    NNP      .  ...      NaN      NaN    NaN    NaN   \n",
       "3        Holmes       Mr.    NNP    NNP  ...      NaN      NaN    NaN    NaN   \n",
       "4           NaN  Sherlock    NaN    NNP  ...      NaN      NaN    NaN    NaN   \n",
       "...         ...       ...    ...    ...  ...      ...      ...    ...    ...   \n",
       "65446        of    russet     IN     NN  ...      NaN    until    NaN     IN   \n",
       "65447       the     slope     DT    NNS  ...      NaN       it    NaN    PRP   \n",
       "65448      moor        of     NN     IN  ...      NaN    merge    NaN    VBD   \n",
       "65449         .       the      .     DT  ...      NaN     into    NaN     IN   \n",
       "65450       NaN      moor    NaN     NN  ...      NaN      the    NaN     DT   \n",
       "\n",
       "      lemma_a7 lemma_b7 pos_a7 pos_b7 known_cue negCue  \n",
       "0          NaN      NaN    NaN    NaN     False      0  \n",
       "1          NaN      NaN    NaN    NaN     False      0  \n",
       "2          NaN      NaN    NaN    NaN     False      0  \n",
       "3          NaN      NaN    NaN    NaN     False      0  \n",
       "4          NaN      NaN    NaN    NaN     False      0  \n",
       "...        ...      ...    ...    ...       ...    ...  \n",
       "65446      NaN     away    NaN     RB     False      0  \n",
       "65447      NaN    until    NaN     IN     False      0  \n",
       "65448      NaN       it    NaN    PRP     False      0  \n",
       "65449      NaN    merge    NaN    VBD     False      0  \n",
       "65450      NaN     into    NaN     IN     False      0  \n",
       "\n",
       "[65451 rows x 36 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('corpus/train_df_preproc.csv', sep='\\t')\n",
    "test_df = pd.read_csv('corpus/test_df_preproc.csv', sep='\\t')\n",
    "\n",
    "train_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Predicting with different set of features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Window = 7 and Known Cues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######################################################################################\n",
      "WINDOW = 7, KNOWN_CUES = TRUE\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     13388\n",
      "           1       0.96      0.87      0.91       176\n",
      "           2       1.00      0.67      0.80         3\n",
      "\n",
      "    accuracy                           1.00     13567\n",
      "   macro avg       0.98      0.85      0.90     13567\n",
      "weighted avg       1.00      1.00      1.00     13567\n",
      "\n",
      "#######################################################################################\n",
      "WINDOW = 7, KNOWN_CUES = FALSE\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     13388\n",
      "           1       0.95      0.78      0.86       176\n",
      "           2       1.00      0.67      0.80         3\n",
      "\n",
      "    accuracy                           1.00     13567\n",
      "   macro avg       0.98      0.81      0.88     13567\n",
      "weighted avg       1.00      1.00      1.00     13567\n",
      "\n",
      "#######################################################################################\n",
      "WINDOW = 6, KNOWN_CUES = TRUE\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     13388\n",
      "           1       0.94      0.87      0.90       176\n",
      "           2       1.00      0.67      0.80         3\n",
      "\n",
      "    accuracy                           1.00     13567\n",
      "   macro avg       0.98      0.85      0.90     13567\n",
      "weighted avg       1.00      1.00      1.00     13567\n",
      "\n",
      "#######################################################################################\n",
      "WINDOW = 6, KNOWN_CUES = FALSE\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     13388\n",
      "           1       0.93      0.77      0.84       176\n",
      "           2       1.00      0.67      0.80         3\n",
      "\n",
      "    accuracy                           1.00     13567\n",
      "   macro avg       0.98      0.81      0.88     13567\n",
      "weighted avg       1.00      1.00      1.00     13567\n",
      "\n",
      "#######################################################################################\n",
      "WINDOW = 5, KNOWN_CUES = TRUE\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     13388\n",
      "           1       0.93      0.87      0.90       176\n",
      "           2       1.00      0.67      0.80         3\n",
      "\n",
      "    accuracy                           1.00     13567\n",
      "   macro avg       0.98      0.85      0.90     13567\n",
      "weighted avg       1.00      1.00      1.00     13567\n",
      "\n",
      "#######################################################################################\n",
      "WINDOW = 5, KNOWN_CUES = FALSE\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     13388\n",
      "           1       0.92      0.81      0.86       176\n",
      "           2       1.00      0.67      0.80         3\n",
      "\n",
      "    accuracy                           1.00     13567\n",
      "   macro avg       0.97      0.82      0.89     13567\n",
      "weighted avg       1.00      1.00      1.00     13567\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"#######################################################################################\")\n",
    "print(\"WINDOW = 7, KNOWN_CUES = TRUE\")\n",
    "\n",
    "train_df_w7_kc = train_df \n",
    "test_df_w7_kc  = test_df \n",
    "\n",
    "X_train_w7_kc, y_train = dataframe2features(train_df_w7_kc)\n",
    "X_test_w7_kc,  y_test  = dataframe2features(test_df_w7_kc)\n",
    "\n",
    "crf_w7_kc, report_w7_kc = train_crf_and_predict(X_train_w7_kc,y_train,X_test_w7_kc,test_df_w7_kc['negCue'])\n",
    "\n",
    "print(\"#######################################################################################\")\n",
    "print(\"WINDOW = 7, KNOWN_CUES = FALSE\")\n",
    "\n",
    "train_df_w7 = train_df.drop(columns=['known_cue'])\n",
    "test_df_w7  = test_df.drop(columns=['known_cue'])\n",
    "\n",
    "X_train_w7, y_train = dataframe2features(train_df_w7,known_cues=False)\n",
    "X_test_w7,  y_test  = dataframe2features(test_df_w7,known_cues=False)\n",
    "\n",
    "crf_w7, report_w7 = train_crf_and_predict(X_train_w7,y_train,X_test_w7,test_df_w7['negCue'])\n",
    "\n",
    "print(\"#######################################################################################\")\n",
    "print(\"WINDOW = 6, KNOWN_CUES = TRUE\")\n",
    "\n",
    "train_df_w6_kc = train_df.drop(columns=['lemma_a7','lemma_b7','pos_a7','pos_b7']) \n",
    "test_df_w6_kc  = test_df.drop(columns=['lemma_a7','lemma_b7','pos_a7','pos_b7']) \n",
    "\n",
    "X_train_w6_kc, y_train = dataframe2features(train_df_w6_kc,window=6)\n",
    "X_test_w6_kc,  y_test  = dataframe2features(test_df_w6_kc,window=6)\n",
    "\n",
    "crf_w6_kc, report_w6_kc = train_crf_and_predict(X_train_w6_kc,y_train,X_test_w6_kc,test_df_w6_kc['negCue'])\n",
    "\n",
    "print(\"#######################################################################################\")\n",
    "print(\"WINDOW = 6, KNOWN_CUES = FALSE\")\n",
    "\n",
    "train_df_w6 = train_df.drop(columns=['lemma_a7','lemma_b7','pos_a7','pos_b7','known_cue'])\n",
    "test_df_w6  = test_df.drop(columns=['lemma_a7','lemma_b7','pos_a7','pos_b7','known_cue'])\n",
    "\n",
    "X_train_w6, y_train = dataframe2features(train_df_w6,known_cues=False,window=6)\n",
    "X_test_w6,  y_test  = dataframe2features(test_df_w6,known_cues=False,window=6)\n",
    "\n",
    "crf_w6, report_w6 = train_crf_and_predict(X_train_w6,y_train,X_test_w6,test_df_w6['negCue'])\n",
    "\n",
    "print(\"#######################################################################################\")\n",
    "print(\"WINDOW = 5, KNOWN_CUES = TRUE\")\n",
    "\n",
    "train_df_w5_kc = train_df.drop(columns=['lemma_a7','lemma_b7','pos_a7','pos_b7','lemma_a6','lemma_b6','pos_a6','pos_b6']) \n",
    "test_df_w5_kc  = test_df.drop(columns=['lemma_a7','lemma_b7','pos_a7','pos_b7','lemma_a6','lemma_b6','pos_a6','pos_b6']) \n",
    "\n",
    "X_train_w5_kc, y_train = dataframe2features(train_df_w5_kc,window=5)\n",
    "X_test_w5_kc,  y_test  = dataframe2features(test_df_w5_kc,window=5)\n",
    "\n",
    "crf_w5_kc, report_w5_kc = train_crf_and_predict(X_train_w5_kc,y_train,X_test_w5_kc,test_df_w5_kc['negCue'])\n",
    "\n",
    "print(\"#######################################################################################\")\n",
    "print(\"WINDOW = 5, KNOWN_CUES = FALSE\")\n",
    "\n",
    "train_df_w5 = train_df.drop(columns=['lemma_a7','lemma_b7','pos_a7','pos_b7','known_cue','lemma_a6','lemma_b6','pos_a6','pos_b6'])\n",
    "test_df_w5  = test_df.drop(columns=['lemma_a7','lemma_b7','pos_a7','pos_b7','known_cue','lemma_a6','lemma_b6','pos_a6','pos_b6'])\n",
    "\n",
    "X_train_w5, y_train = dataframe2features(train_df_w5,known_cues=False,window=5)\n",
    "X_test_w5,  y_test  = dataframe2features(test_df_w5,known_cues=False,window=5)\n",
    "\n",
    "crf_w5, report_w5 = train_crf_and_predict(X_train_w5,y_train,X_test_w5,test_df_w5['negCue'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "13562    0\n",
       "13563    0\n",
       "13564    0\n",
       "13565    0\n",
       "13566    0\n",
       "Name: negCue, Length: 13567, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asd = test_df_w7_kc['negCue']\n",
    "\n",
    "asd = asd.astype({'negCue': str})\n",
    "asd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Window = 7 and NOT Known Cues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Training Finished! #######\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     13388\n",
      "           1       0.95      0.78      0.86       176\n",
      "           2       1.00      0.67      0.80         3\n",
      "\n",
      "    accuracy                           1.00     13567\n",
      "   macro avg       0.98      0.81      0.88     13567\n",
      "weighted avg       1.00      1.00      1.00     13567\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Martin\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\base.py:209: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
      "  warnings.warn('From version 0.24, get_params will raise an '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(CRF(algorithm='lbfgs', all_possible_transitions=True, c1=0.1, c2=0.1,\n",
       "     keep_tempfiles=None, max_iterations=100),\n",
       " '              precision    recall  f1-score   support\\n\\n           0       1.00      1.00      1.00     13388\\n           1       0.95      0.78      0.86       176\\n           2       1.00      0.67      0.80         3\\n\\n    accuracy                           1.00     13567\\n   macro avg       0.98      0.81      0.88     13567\\nweighted avg       1.00      1.00      1.00     13567\\n')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_w7 = train_df.drop(columns=['known_cue'])\n",
    "test_df_w7  = test_df.drop(columns=['known_cue'])\n",
    "\n",
    "X_train_w7, y_train = dataframe2features(train_df_w7,known_cues=False)\n",
    "X_test_w7,  y_test  = dataframe2features(test_df_w7,known_cues=False)\n",
    "\n",
    "crf_w7, report_w7 = train_crf_and_predict(X_train_w7,y_train,X_test_w7,test_df_w7['negCue'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'test_df' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8904/724245617.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_crf_and_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_w7\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_test_w7\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_df_w7\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'negCue'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8904/3533832677.py\u001b[0m in \u001b[0;36mtrain_crf_and_predict\u001b[1;34m(X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[0;32m    191\u001b[0m         \u001b[0my_pred_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence_preds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m     \u001b[0mtest_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'pred'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_pred_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m     \u001b[0mtest_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"negCue\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'test_df' referenced before assignment"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     13388\n",
      "           1       0.95      0.78      0.86       176\n",
      "           2       1.00      0.67      0.80         3\n",
      "\n",
      "    accuracy                           1.00     13567\n",
      "   macro avg       0.98      0.81      0.88     13567\n",
      "weighted avg       1.00      1.00      1.00     13567\n",
      "\n"
     ]
    }
   ],
   "source": [
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.1,\n",
    "    c2=0.1,\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "\n",
    "crf.fit(X_train_w7, y_train)\n",
    "\n",
    "labels = list(crf.classes_)\n",
    "sorted_labels = sorted(labels, key=lambda name: (name[1:], name[0]))\n",
    "\n",
    "y_pred = crf.predict(X_test_w7)\n",
    "y_pred_ = []\n",
    "\n",
    "for sentence_preds in y_pred:\n",
    "    y_pred_.extend(sentence_preds)\n",
    "\n",
    "test_df['pred'] = y_pred_\n",
    "test_df = test_df.astype({\"negCue\": str})\n",
    "\n",
    "\n",
    "print(classification_report(test_df_w7['negCue'], y_pred_ , target_names=sorted_labels))\n",
    "# print(classification_report(test_df['negCue'], test_df['pred']  , target_names=sorted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Martin\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\base.py:209: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
      "  warnings.warn('From version 0.24, get_params will raise an '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_transitions=True, c1=0.1, c2=0.1,\n",
       "    keep_tempfiles=None, max_iterations=100)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.1,\n",
    "    c2=0.1,\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "\n",
    "crf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     13388\n",
      "           1       0.96      0.87      0.91       176\n",
      "           2       1.00      0.67      0.80         3\n",
      "\n",
      "    accuracy                           1.00     13567\n",
      "   macro avg       0.98      0.85      0.90     13567\n",
      "weighted avg       1.00      1.00      1.00     13567\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels = list(crf.classes_)\n",
    "sorted_labels = sorted(labels, key=lambda name: (name[1:], name[0]))\n",
    "\n",
    "y_pred = crf.predict(X_test)\n",
    "y_pred_ = []\n",
    "\n",
    "for sentence_preds in y_pred:\n",
    "    y_pred_.extend(sentence_preds)\n",
    "\n",
    "test_df['pred'] = y_pred_\n",
    "test_df = test_df.astype({\"negCue\": str})\n",
    "\n",
    "\n",
    "print(classification_report(test_df['negCue'], test_df['pred'], target_names=sorted_labels))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper parameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:  5.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params: {'c1': 1.1210252392427602, 'c2': 0.031129825505882648}\n"
     ]
    }
   ],
   "source": [
    "# define fixed parameters and parameters to search\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "params_space = {\n",
    "    'c1': scipy.stats.expon(scale=0.5),\n",
    "    'c2': scipy.stats.expon(scale=0.05),\n",
    "}\n",
    "\n",
    "# use the same metric for evaluation\n",
    "f1_scorer = make_scorer(metrics.flat_f1_score,\n",
    "                        average='weighted', labels=labels)\n",
    "\n",
    "# search\n",
    "rs = RandomizedSearchCV(crf, params_space,\n",
    "                        cv=3,\n",
    "                        verbose=1,\n",
    "                        n_jobs=-1,\n",
    "                        n_iter=50,\n",
    "                        scoring=f1_scorer)\n",
    "\n",
    "rs.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print('best params:', rs.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8904/2708394347.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m )\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mcrf_hyper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Martin\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn_crfsuite\\estimator.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, X_dev, y_dev)\u001b[0m\n\u001b[0;32m    329\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 331\u001b[1;33m         \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodelfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mholdout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mX_dev\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    332\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_log_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogparser\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpycrfsuite/_pycrfsuite.pyx\u001b[0m in \u001b[0;36mpycrfsuite._pycrfsuite.BaseTrainer.train\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpycrfsuite/_pycrfsuite.pyx\u001b[0m in \u001b[0;36mpycrfsuite._pycrfsuite.BaseTrainer._on_message\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpycrfsuite/_pycrfsuite.pyx\u001b[0m in \u001b[0;36mpycrfsuite._pycrfsuite.Trainer.message\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Martin\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pycrfsuite\\_logparser.py\u001b[0m in \u001b[0;36mfeed\u001b[1;34m(self, line)\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfeed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;31m# if line != '\\n':\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'STARTING'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "crf_hyper = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=1.121,\n",
    "    c2=0.031,\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "\n",
    "crf_hyper.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "labels = list(crf_hyper.classes_)\n",
    "\n",
    "y_pred = crf_hyper.predict(X_test)\n",
    "# y_pred_ = MultiLabelBinarizer().fit_transform(y_pred)\n",
    "\n",
    "y_pred_ = []\n",
    "for sentence_preds in y_pred:\n",
    "    y_pred_.extend(sentence_preds)\n",
    "\n",
    "test_df['pred'] = y_pred_\n",
    "test_df = test_df.astype({\"negCue\": str})\n",
    "\n",
    "# group B and I results\n",
    "sorted_labels = sorted(\n",
    "    labels,\n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")\n",
    "\n",
    "print(classification_report(test_df['negCue'], test_df['pred'], target_names=sorted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>sentence</th>\n",
       "      <th>position</th>\n",
       "      <th>token</th>\n",
       "      <th>lemma</th>\n",
       "      <th>postag</th>\n",
       "      <th>lemma_a1</th>\n",
       "      <th>lemma_b1</th>\n",
       "      <th>pos_a1</th>\n",
       "      <th>pos_b1</th>\n",
       "      <th>...</th>\n",
       "      <th>lemma_a6</th>\n",
       "      <th>lemma_b6</th>\n",
       "      <th>pos_a6</th>\n",
       "      <th>pos_b6</th>\n",
       "      <th>lemma_a7</th>\n",
       "      <th>lemma_b7</th>\n",
       "      <th>pos_a7</th>\n",
       "      <th>pos_b7</th>\n",
       "      <th>known_cue</th>\n",
       "      <th>negCue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baskervilles01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Chapter</td>\n",
       "      <td>chapter</td>\n",
       "      <td>NN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>baskervilles01</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>baskervilles01</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>NNP</td>\n",
       "      <td>Sherlock</td>\n",
       "      <td>.</td>\n",
       "      <td>NNP</td>\n",
       "      <td>.</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>baskervilles01</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Sherlock</td>\n",
       "      <td>Sherlock</td>\n",
       "      <td>NNP</td>\n",
       "      <td>Holmes</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NNP</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>baskervilles01</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Holmes</td>\n",
       "      <td>Holmes</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sherlock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65446</th>\n",
       "      <td>baskervilles14</td>\n",
       "      <td>270</td>\n",
       "      <td>58</td>\n",
       "      <td>slopes</td>\n",
       "      <td>slope</td>\n",
       "      <td>NNS</td>\n",
       "      <td>of</td>\n",
       "      <td>russet</td>\n",
       "      <td>IN</td>\n",
       "      <td>NN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>until</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>away</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RB</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65447</th>\n",
       "      <td>baskervilles14</td>\n",
       "      <td>270</td>\n",
       "      <td>59</td>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>the</td>\n",
       "      <td>slope</td>\n",
       "      <td>DT</td>\n",
       "      <td>NNS</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>it</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PRP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>until</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IN</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65448</th>\n",
       "      <td>baskervilles14</td>\n",
       "      <td>270</td>\n",
       "      <td>60</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>moor</td>\n",
       "      <td>of</td>\n",
       "      <td>NN</td>\n",
       "      <td>IN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>merge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VBD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>it</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PRP</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65449</th>\n",
       "      <td>baskervilles14</td>\n",
       "      <td>270</td>\n",
       "      <td>61</td>\n",
       "      <td>moor</td>\n",
       "      <td>moor</td>\n",
       "      <td>NN</td>\n",
       "      <td>.</td>\n",
       "      <td>the</td>\n",
       "      <td>.</td>\n",
       "      <td>DT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>into</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>merge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VBD</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65450</th>\n",
       "      <td>baskervilles14</td>\n",
       "      <td>270</td>\n",
       "      <td>62</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>moor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>into</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IN</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65451 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 file  sentence  position     token     lemma postag  \\\n",
       "0      baskervilles01         0         0   Chapter   chapter     NN   \n",
       "1      baskervilles01         0         1        1.       NaN    NaN   \n",
       "2      baskervilles01         0         2       Mr.       Mr.    NNP   \n",
       "3      baskervilles01         0         3  Sherlock  Sherlock    NNP   \n",
       "4      baskervilles01         0         4    Holmes    Holmes    NNP   \n",
       "...               ...       ...       ...       ...       ...    ...   \n",
       "65446  baskervilles14       270        58    slopes     slope    NNS   \n",
       "65447  baskervilles14       270        59        of        of     IN   \n",
       "65448  baskervilles14       270        60       the       the     DT   \n",
       "65449  baskervilles14       270        61      moor      moor     NN   \n",
       "65450  baskervilles14       270        62         .         .      .   \n",
       "\n",
       "       lemma_a1  lemma_b1 pos_a1 pos_b1  ... lemma_a6 lemma_b6 pos_a6 pos_b6  \\\n",
       "0             1       NaN     CD    NaN  ...      NaN      NaN    NaN    NaN   \n",
       "1           NaN       NaN    NaN    NaN  ...      NaN      NaN    NaN    NaN   \n",
       "2      Sherlock         .    NNP      .  ...      NaN      NaN    NaN    NaN   \n",
       "3        Holmes       Mr.    NNP    NNP  ...      NaN      NaN    NaN    NaN   \n",
       "4           NaN  Sherlock    NaN    NNP  ...      NaN      NaN    NaN    NaN   \n",
       "...         ...       ...    ...    ...  ...      ...      ...    ...    ...   \n",
       "65446        of    russet     IN     NN  ...      NaN    until    NaN     IN   \n",
       "65447       the     slope     DT    NNS  ...      NaN       it    NaN    PRP   \n",
       "65448      moor        of     NN     IN  ...      NaN    merge    NaN    VBD   \n",
       "65449         .       the      .     DT  ...      NaN     into    NaN     IN   \n",
       "65450       NaN      moor    NaN     NN  ...      NaN      the    NaN     DT   \n",
       "\n",
       "      lemma_a7 lemma_b7 pos_a7 pos_b7 known_cue negCue  \n",
       "0          NaN      NaN    NaN    NaN     False      0  \n",
       "1          NaN      NaN    NaN    NaN     False      0  \n",
       "2          NaN      NaN    NaN    NaN     False      0  \n",
       "3          NaN      NaN    NaN    NaN     False      0  \n",
       "4          NaN      NaN    NaN    NaN     False      0  \n",
       "...        ...      ...    ...    ...       ...    ...  \n",
       "65446      NaN     away    NaN     RB     False      0  \n",
       "65447      NaN    until    NaN     IN     False      0  \n",
       "65448      NaN       it    NaN    PRP     False      0  \n",
       "65449      NaN    merge    NaN    VBD     False      0  \n",
       "65450      NaN     into    NaN     IN     False      0  \n",
       "\n",
       "[65451 rows x 36 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_27624/1858196609.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_df\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'train_df' is not defined"
     ]
    }
   ],
   "source": [
    "train_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a1d88f1d6af7274392319340ad589157e5034eb25853bd7ff5b502ff0dd39369"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
